{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKwANp8L8Bj3qRrN1zmyIx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darshannayak21/pds/blob/main/exp_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "SKILL expriment 2:\n",
        "\n",
        "Imoprting neccessary libraries (like pandas and numpy here)\n",
        "Import the two datasets.\n",
        "Perform data cleaning process: 1. Remove all the null values from the merged and concatinated data. 2. Find information of the data by the .info () function in python. 3. Describe the datasets using .describe() function in python. 4. Check whether there exist any null or missing values in the datasets by using .isnull().any() function. 5. Check for duplicate values in the datasets if any using .duplicated() function. 6. Drop the duplicate values from the datasets using the drop_duplicates() function. 7. Fill the missing values (null values) with some value . 8. Count the non-null values from any particular column from any dataset by specifying the column name."
      ],
      "metadata": {
        "id": "tEyVTRyEc-pI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGE5Bfx3cM53",
        "outputId": "3860464a-8c90-4ea7-f6d0-34dc6cc23405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "info\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3000 entries, 0 to 2999\n",
            "Data columns (total 9 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   longitude           3000 non-null   float64\n",
            " 1   latitude            3000 non-null   float64\n",
            " 2   housing_median_age  3000 non-null   float64\n",
            " 3   total_rooms         3000 non-null   float64\n",
            " 4   total_bedrooms      3000 non-null   float64\n",
            " 5   population          3000 non-null   float64\n",
            " 6   households          3000 non-null   float64\n",
            " 7   median_income       3000 non-null   float64\n",
            " 8   median_house_value  3000 non-null   float64\n",
            "dtypes: float64(9)\n",
            "memory usage: 211.1 KB\n",
            "None\n",
            "describe\n",
            "         longitude    latitude  housing_median_age   total_rooms  \\\n",
            "count  3000.000000  3000.00000         3000.000000   3000.000000   \n",
            "mean   -119.589200    35.63539           28.845333   2599.578667   \n",
            "std       1.994936     2.12967           12.555396   2155.593332   \n",
            "min    -124.180000    32.56000            1.000000      6.000000   \n",
            "25%    -121.810000    33.93000           18.000000   1401.000000   \n",
            "50%    -118.485000    34.27000           29.000000   2106.000000   \n",
            "75%    -118.020000    37.69000           37.000000   3129.000000   \n",
            "max    -114.490000    41.92000           52.000000  30450.000000   \n",
            "\n",
            "       total_bedrooms    population  households  median_income  \\\n",
            "count     3000.000000   3000.000000  3000.00000    3000.000000   \n",
            "mean       529.950667   1402.798667   489.91200       3.807272   \n",
            "std        415.654368   1030.543012   365.42271       1.854512   \n",
            "min          2.000000      5.000000     2.00000       0.499900   \n",
            "25%        291.000000    780.000000   273.00000       2.544000   \n",
            "50%        437.000000   1155.000000   409.50000       3.487150   \n",
            "75%        636.000000   1742.750000   597.25000       4.656475   \n",
            "max       5419.000000  11935.000000  4930.00000      15.000100   \n",
            "\n",
            "       median_house_value  \n",
            "count          3000.00000  \n",
            "mean         205846.27500  \n",
            "std          113119.68747  \n",
            "min           22500.00000  \n",
            "25%          121200.00000  \n",
            "50%          177650.00000  \n",
            "75%          263975.00000  \n",
            "max          500001.00000  \n",
            "IS NULL any\n",
            "longitude             False\n",
            "latitude              False\n",
            "housing_median_age    False\n",
            "total_rooms           False\n",
            "total_bedrooms        False\n",
            "population            False\n",
            "households            False\n",
            "median_income         False\n",
            "median_house_value    False\n",
            "dtype: bool\n",
            "isnullsum\n",
            "longitude             0\n",
            "latitude              0\n",
            "housing_median_age    0\n",
            "total_rooms           0\n",
            "total_bedrooms        0\n",
            "population            0\n",
            "households            0\n",
            "median_income         0\n",
            "median_house_value    0\n",
            "dtype: int64\n",
            "duplicated\n",
            "0       False\n",
            "1       False\n",
            "2       False\n",
            "3       False\n",
            "4       False\n",
            "        ...  \n",
            "2995    False\n",
            "2996    False\n",
            "2997    False\n",
            "2998    False\n",
            "2999    False\n",
            "Length: 3000, dtype: bool\n",
            "drop duplicates\n",
            "None\n",
            "DROPNA\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "url1 = \"/content/sample_data/california_housing_test.csv\"\n",
        "\n",
        "dataset1 = pd.read_csv(url1)\n",
        "\n",
        "#conc_data= pd.concat([dataset1,dataset2])\n",
        "\n",
        "print(\"info\")\n",
        "print(dataset1.info())\n",
        "\n",
        "print(\"describe\")\n",
        "print(dataset1.describe())\n",
        "\n",
        "print(\"IS NULL any\")\n",
        "print(dataset1.isnull().any())\n",
        "print(\"isnullsum\")\n",
        "print(dataset1.isnull().sum())\n",
        "print(\"duplicated\")\n",
        "print(dataset1.duplicated())\n",
        "print(\"drop duplicates\")\n",
        "print(dataset1.drop_duplicates(inplace=True))\n",
        "print(\"DROPNA\")\n",
        "print(dataset1.dropna(inplace=True))"
      ]
    }
  ]
}